{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "## Description\n",
    "A sentiment analysis job about the problems of each major U.S. airline. <br/>\n",
    "Twitter data was scraped from February of 2015 and contributors were asked to:\n",
    "- Classify positive, negative, and neutral tweets.\n",
    "- Categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
    "\n",
    "## Dataset\n",
    "The dataset has to be downloaded from: https://www.kaggle.com/crowdflower/twitter-airline-sentiment<br/>\n",
    "* tweet_id\n",
    "* airline_sentiment\n",
    "* airline_sentiment_confidence\n",
    "* negativereason\n",
    "* negativereason_confidence\n",
    "* airline\n",
    "* airline_sentiment_gold\n",
    "* name\n",
    "* negativereason_gold\n",
    "* retweet_count\n",
    "* text\n",
    "* tweet_coord\n",
    "* tweet_created\n",
    "* tweet_location\n",
    "* user_timezone\n",
    "\n",
    "# Objective\n",
    "To implement the techniques learnt as a part of the course.\n",
    "\n",
    "# Learning Outcomes\n",
    "- Basic understanding of text pre-processing.\n",
    "- What to do after text pre-processing:\n",
    "    - Bag of words\n",
    "    - Tf-idf\n",
    "- Build the classification model.\n",
    "- Evaluate the Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0) # Display full dataframe information (Non-turncated Text column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      "tweet_id                        14640 non-null int64\n",
      "airline_sentiment               14640 non-null object\n",
      "airline_sentiment_confidence    14640 non-null float64\n",
      "negativereason                  9178 non-null object\n",
      "negativereason_confidence       10522 non-null float64\n",
      "airline                         14640 non-null object\n",
      "airline_sentiment_gold          40 non-null object\n",
      "name                            14640 non-null object\n",
      "negativereason_gold             32 non-null object\n",
      "retweet_count                   14640 non-null int64\n",
      "text                            14640 non-null object\n",
      "tweet_coord                     1019 non-null object\n",
      "tweet_created                   14640 non-null object\n",
      "tweet_location                  9907 non-null object\n",
      "user_timezone                   9820 non-null object\n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "tweetsData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns have null values:\n",
    "* negativereason\n",
    "* negativereason_confidence\n",
    "* airline_sentiment_gold\n",
    "* negativereason_gold\n",
    "* tweet_coord\n",
    "* tweet_location\n",
    "* user_timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513  neutral           1.0000                         \n",
       "1  570301130888122368  positive          0.3486                         \n",
       "2  570301083672813571  neutral           0.6837                         \n",
       "3  570301031407624196  negative          1.0000                         \n",
       "4  570300817074462722  negative          1.0000                         \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0  NaN           NaN                         Virgin America   \n",
       "1  NaN            0.0000                     Virgin America   \n",
       "2  NaN           NaN                         Virgin America   \n",
       "3  Bad Flight     0.7033                     Virgin America   \n",
       "4  Can't Tell     1.0000                     Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0  NaN                    cairdin     NaN                 0               \n",
       "1  NaN                    jnardino    NaN                 0               \n",
       "2  NaN                    yvonnalynn  NaN                 0               \n",
       "3  NaN                    jnardino    NaN                 0               \n",
       "4  NaN                    jnardino    NaN                 0               \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0  NaN         2015-02-24 11:35:52 -0800  NaN             \n",
       "1  NaN         2015-02-24 11:15:59 -0800  NaN             \n",
       "2  NaN         2015-02-24 11:15:48 -0800  Lets Play       \n",
       "3  NaN         2015-02-24 11:15:36 -0800  NaN             \n",
       "4  NaN         2015-02-24 11:14:45 -0800  NaN             \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America    504 \n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData[\"airline\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData[\"airline_sentiment\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                            5462\n",
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight               847 \n",
       "Lost Luggage                   724 \n",
       "Bad Flight                     580 \n",
       "Flight Booking Problems        529 \n",
       "Flight Attendant Complaints    481 \n",
       "longlines                      178 \n",
       "Damaged Luggage                74  \n",
       "Name: negativereason, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData[\"negativereason\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN         14600\n",
       "negative    32   \n",
       "positive    5    \n",
       "neutral     3    \n",
       "Name: airline_sentiment_gold, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData[\"airline_sentiment_gold\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                         14608\n",
       "Customer Service Issue                      12   \n",
       "Late Flight                                 4    \n",
       "Can't Tell                                  3    \n",
       "Cancelled Flight                            3    \n",
       "Cancelled Flight\\nCustomer Service Issue    2    \n",
       "Lost Luggage\\nDamaged Luggage               1    \n",
       "Flight Attendant Complaints                 1    \n",
       "Customer Service Issue\\nCan't Tell          1    \n",
       "Bad Flight                                  1    \n",
       "Late Flight\\nLost Luggage                   1    \n",
       "Customer Service Issue\\nLost Luggage        1    \n",
       "Late Flight\\nFlight Attendant Complaints    1    \n",
       "Late Flight\\nCancelled Flight               1    \n",
       "Name: negativereason_gold, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData[\"negativereason_gold\"].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Drop all other columns except “text” and “airline_sentiment”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsData_reduced = tweetsData[[\"text\", \"airline_sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Shape of new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Print first 5 rows of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "  airline_sentiment  \n",
       "0  neutral           \n",
       "1  positive          \n",
       "2  neutral           \n",
       "3  negative          \n",
       "4  negative          "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData_reduced.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Text pre-processing: HTML tag removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an hour early. You're too good to me.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                                        \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                                   \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                                    \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse                 \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                                    \n",
       "5  @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\\nit's really the only bad thing about flying VA   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :)                                                            \n",
       "7  @VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP                               \n",
       "8  @virginamerica Well, I didn't…but NOW I DO! :-D                                                                                            \n",
       "9  @VirginAmerica it was amazing, and arrived an hour early. You're too good to me.                                                           \n",
       "\n",
       "  airline_sentiment  \n",
       "0  neutral           \n",
       "1  positive          \n",
       "2  neutral           \n",
       "3  negative          \n",
       "4  negative          \n",
       "5  negative          \n",
       "6  positive          \n",
       "7  neutral           \n",
       "8  positive          \n",
       "9  positive          "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "tweetsData_reduced['text'] = tweetsData_reduced['text'].apply(lambda x: strip_html(x))\n",
    "tweetsData_reduced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On line 3, \"$&amp;$\" was converted back to \"&\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Text pre-processing: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &amp;, they, have, little, recourse]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[@, VirginAmerica, seriously, would, pay, $, 30, a, flight, for, seats, that, did, n't, have, this, playing, ., it, 's, really, the, only, bad, thing, about, flying, VA]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[@, VirginAmerica, yes, ,, nearly, every, time, I, fly, VX, this, “, ear, worm, ”, won, ’, t, go, away, :, )]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[@, VirginAmerica, Really, missed, a, prime, opportunity, for, Men, Without, Hats, parody, ,, there, ., https, :, //t.co/mWpG7grEZP]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[@, virginamerica, Well, ,, I, didn't…but, NOW, I, DO, !, :, -D]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[@, VirginAmerica, it, was, amazing, ,, and, arrived, an, hour, early, ., You, 're, too, good, to, me, .]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                        text  \\\n",
       "0  [@, VirginAmerica, What, @, dhepburn, said, .]                                                                                                                              \n",
       "1  [@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]                                                                                  \n",
       "2  [@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]                                                                                \n",
       "3  [@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &, they, have, little, recourse]                    \n",
       "4  [@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]                                                                                                      \n",
       "5  [@, VirginAmerica, seriously, would, pay, $, 30, a, flight, for, seats, that, did, n't, have, this, playing, ., it, 's, really, the, only, bad, thing, about, flying, VA]   \n",
       "6  [@, VirginAmerica, yes, ,, nearly, every, time, I, fly, VX, this, “, ear, worm, ”, won, ’, t, go, away, :, )]                                                               \n",
       "7  [@, VirginAmerica, Really, missed, a, prime, opportunity, for, Men, Without, Hats, parody, ,, there, ., https, :, //t.co/mWpG7grEZP]                                        \n",
       "8  [@, virginamerica, Well, ,, I, didn't…but, NOW, I, DO, !, :, -D]                                                                                                            \n",
       "9  [@, VirginAmerica, it, was, amazing, ,, and, arrived, an, hour, early, ., You, 're, too, good, to, me, .]                                                                   \n",
       "\n",
       "  airline_sentiment  \n",
       "0  neutral           \n",
       "1  positive          \n",
       "2  neutral           \n",
       "3  negative          \n",
       "4  negative          \n",
       "5  negative          \n",
       "6  positive          \n",
       "7  neutral           \n",
       "8  positive          \n",
       "9  positive          "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer.\n",
    "\n",
    "tweetsData_reduced['text'] = tweetsData_reduced.apply(lambda row: word_tokenize(row['text']), axis=1) # Tokenization of data\n",
    "\n",
    "tweetsData_reduced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Text pre-processing: Remove the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'\\d+', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Text pre-processing: Removal of Special Characters and Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords                       # Import stopwords.\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "customlist = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
    "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
    "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
    "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "# Set custom stop-word's list as not, couldn't etc. words matter in Sentiment, so not removing them from original data.\n",
    "stopwords = list(set(stopwords) - set(customlist)) \n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Text pre-processing: Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Text pre-processing: Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer         # Import Lemmatizer.\n",
    "import nltk\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    \n",
    "    for word, pos in nltk.pos_tag(words):\n",
    "        if (word != ''):\n",
    "            new_words.append(lemmatizer.lemmatize(word, get_wordnet_pos(pos)))        \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Text pre-processing: Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def normalize(words):\n",
    "    words = remove_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = lemmatize_list(words)\n",
    "    return ' '.join(words)\n",
    "\n",
    "tweetsData_reduced['text'] = tweetsData_reduced.apply(lambda row: normalize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>virginamerica what dhepburn say</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>virginamerica plus added commercial experience tacky</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>virginamerica i nt today must mean i need take another trip</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>virginamerica really aggressive blast obnoxious entertainment guest face little recourse</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>virginamerica seriously would pay flight seat nt play really bad thing fly va</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>virginamerica yes nearly every time i fly vx ear worm win go away</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>virginamerica really miss prime opportunity men without hat parody https tcomwpggrezp</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>virginamerica well i didntbut now i do d</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>virginamerica amaze arrive hour early you good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       text  \\\n",
       "0  virginamerica what dhepburn say                                                            \n",
       "1  virginamerica plus added commercial experience tacky                                       \n",
       "2  virginamerica i nt today must mean i need take another trip                                \n",
       "3  virginamerica really aggressive blast obnoxious entertainment guest face little recourse   \n",
       "4  virginamerica really big bad thing                                                         \n",
       "5  virginamerica seriously would pay flight seat nt play really bad thing fly va              \n",
       "6  virginamerica yes nearly every time i fly vx ear worm win go away                          \n",
       "7  virginamerica really miss prime opportunity men without hat parody https tcomwpggrezp      \n",
       "8  virginamerica well i didntbut now i do d                                                   \n",
       "9  virginamerica amaze arrive hour early you good                                             \n",
       "\n",
       "  airline_sentiment  \n",
       "0  neutral           \n",
       "1  positive          \n",
       "2  neutral           \n",
       "3  negative          \n",
       "4  negative          \n",
       "5  negative          \n",
       "6  positive          \n",
       "7  neutral           \n",
       "8  positive          \n",
       "9  positive          "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsData_reduced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Vectorization - Use CountVectorizer + 1000 most-frequently used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "tweetsData_reduced_features_1 = vectorizer.fit_transform(tweetsData_reduced['text'])\n",
    "tweetsData_reduced_features_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Vectorization - Use TfidfVectorizer + 1000 most-frequently used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tweetsData_reduced_features_2 = vectorizer.fit_transform(tweetsData_reduced['text'])\n",
    "tweetsData_reduced_features_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Split 4.1 & 4.2 data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tweetsData_reduced['airline_sentiment']\n",
    "labels = labels.replace(\"neutral\", \"0\").replace(\"negative\", \"-1\").replace(\"positive\", \"1\")\n",
    "labels = labels.astype('int')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(tweetsData_reduced_features_1, labels, test_size=0.3, random_state=1)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(tweetsData_reduced_features_2, labels, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluate model - Use LinearSVC + 4.1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "          verbose=0)\n",
      "0.755327868852459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc1 = LinearSVC(random_state=1)\n",
    "svc1 = svc1.fit(X_train_1, y_train_1)\n",
    "\n",
    "print(svc1)\n",
    "print(np.mean(cross_val_score(svc1, tweetsData_reduced_features_1, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = svc1.predict(X_test_1)\n",
    "acc1 = svc1.score(X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2415  233   93]\n",
      " [ 298  543   95]\n",
      " [ 147  106  462]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Negative</th>\n",
       "      <th>Correct Neutral</th>\n",
       "      <th>Correct Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer 1000</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>2415</td>\n",
       "      <td>543</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  Accuracy  Correct Negative  \\\n",
       "0  LinearSVC + CountVectorizer 1000  0.778689  2415               \n",
       "\n",
       "   Correct Neutral  Correct Positive  \n",
       "0  543              462               "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat_1 = confusion_matrix(y_test_1, result1)\n",
    "print(conf_mat_1)\n",
    "\n",
    "resultsDf = pd.DataFrame({'Method':['LinearSVC + CountVectorizer 1000'],\n",
    "                              'Accuracy': [acc1],\n",
    "                              'Correct Negative': conf_mat_1[0,0], \n",
    "                              'Correct Neutral': conf_mat_1[1,1],\n",
    "                              'Correct Positive': conf_mat_1[2,2]})\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluate model - Use LinearSVC + 4.2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "          verbose=0)\n",
      "0.7626366120218578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc2 = LinearSVC(random_state=1)\n",
    "svc2 = svc2.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(svc2)\n",
    "print(np.mean(cross_val_score(svc2, tweetsData_reduced_features_2, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = svc2.predict(X_test_2)\n",
    "acc2 = svc2.score(X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2461  206   74]\n",
      " [ 342  517   77]\n",
      " [ 164   98  453]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Negative</th>\n",
       "      <th>Correct Neutral</th>\n",
       "      <th>Correct Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer 1000</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>2415</td>\n",
       "      <td>543</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer 1000</td>\n",
       "      <td>0.781193</td>\n",
       "      <td>2461</td>\n",
       "      <td>517</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  Accuracy  Correct Negative  \\\n",
       "0  LinearSVC + CountVectorizer 1000  0.778689  2415               \n",
       "0  LinearSVC + TfidfVectorizer 1000  0.781193  2461               \n",
       "\n",
       "   Correct Neutral  Correct Positive  \n",
       "0  543              462               \n",
       "0  517              453               "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat_2 = confusion_matrix(y_test_2, result2)\n",
    "print(conf_mat_2)\n",
    "\n",
    "resultsDf = pd.concat([resultsDf, pd.DataFrame({'Method':['LinearSVC + TfidfVectorizer 1000'], \n",
    "                          'Accuracy': [acc2],\n",
    "                          'Correct Negative': conf_mat_2[0,0], \n",
    "                          'Correct Neutral': conf_mat_2[1,1],\n",
    "                          'Correct Positive': conf_mat_2[2,2]})])\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Vectorization - Use CountVectorizer + all unigrams, bigrams and trigrams features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 210594)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "tweetsData_reduced_features_3 = vectorizer.fit_transform(tweetsData_reduced['text'])\n",
    "tweetsData_reduced_features_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Vectorization - Use TfidfVectorizer + all unigrams, bigrams and trigrams features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 210594)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "tweetsData_reduced_features_4 = vectorizer.fit_transform(tweetsData_reduced['text'])\n",
    "tweetsData_reduced_features_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Split 6.1 & 6.2 data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tweetsData_reduced['airline_sentiment']\n",
    "labels = labels.replace(\"neutral\", \"0\").replace(\"negative\", \"-1\").replace(\"positive\", \"1\")\n",
    "labels = labels.astype('int')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(tweetsData_reduced_features_3, labels, test_size=0.3, random_state=1)\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(tweetsData_reduced_features_4, labels, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Evaluate model - Use LinearSVC + 6.1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "          verbose=0)\n",
      "0.7616120218579233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc3 = LinearSVC(random_state=1)\n",
    "svc3 = svc1.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(svc3)\n",
    "print(np.mean(cross_val_score(svc3, tweetsData_reduced_features_3, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = svc3.predict(X_test_3)\n",
    "acc3 = svc3.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2399  250   92]\n",
      " [ 284  562   90]\n",
      " [ 114  116  485]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Negative</th>\n",
       "      <th>Correct Neutral</th>\n",
       "      <th>Correct Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer 1000</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>2415</td>\n",
       "      <td>543</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer 1000</td>\n",
       "      <td>0.781193</td>\n",
       "      <td>2461</td>\n",
       "      <td>517</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer all</td>\n",
       "      <td>0.784608</td>\n",
       "      <td>2399</td>\n",
       "      <td>562</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  Accuracy  Correct Negative  \\\n",
       "0  LinearSVC + CountVectorizer 1000  0.778689  2415               \n",
       "0  LinearSVC + TfidfVectorizer 1000  0.781193  2461               \n",
       "0  LinearSVC + CountVectorizer all   0.784608  2399               \n",
       "\n",
       "   Correct Neutral  Correct Positive  \n",
       "0  543              462               \n",
       "0  517              453               \n",
       "0  562              485               "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat_3 = confusion_matrix(y_test_3, result3)\n",
    "print(conf_mat_3)\n",
    "\n",
    "resultsDf = pd.concat([resultsDf, pd.DataFrame({'Method':['LinearSVC + CountVectorizer all'], \n",
    "                          'Accuracy': [acc3],\n",
    "                          'Correct Negative': conf_mat_3[0,0], \n",
    "                          'Correct Neutral': conf_mat_3[1,1],\n",
    "                          'Correct Positive': conf_mat_3[2,2]})])\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Evaluate model -  Use LinearSVC + 6.2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
      "          verbose=0)\n",
      "0.7550546448087432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc4 = LinearSVC(random_state=1)\n",
    "svc4 = svc4.fit(X_train_4, y_train_4)\n",
    "\n",
    "print(svc4)\n",
    "print(np.mean(cross_val_score(svc4, tweetsData_reduced_features_4, labels, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = svc4.predict(X_test_4)\n",
    "acc4 = svc4.score(X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2619   90   32]\n",
      " [ 488  404   44]\n",
      " [ 230   72  413]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Negative</th>\n",
       "      <th>Correct Neutral</th>\n",
       "      <th>Correct Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer 1000</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>2415</td>\n",
       "      <td>543</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer 1000</td>\n",
       "      <td>0.781193</td>\n",
       "      <td>2461</td>\n",
       "      <td>517</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer all</td>\n",
       "      <td>0.784608</td>\n",
       "      <td>2399</td>\n",
       "      <td>562</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer all</td>\n",
       "      <td>0.782332</td>\n",
       "      <td>2619</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  Accuracy  Correct Negative  \\\n",
       "0  LinearSVC + CountVectorizer 1000  0.778689  2415               \n",
       "0  LinearSVC + TfidfVectorizer 1000  0.781193  2461               \n",
       "0  LinearSVC + CountVectorizer all   0.784608  2399               \n",
       "0  LinearSVC + TfidfVectorizer all   0.782332  2619               \n",
       "\n",
       "   Correct Neutral  Correct Positive  \n",
       "0  543              462               \n",
       "0  517              453               \n",
       "0  562              485               \n",
       "0  404              413               "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat_4 = confusion_matrix(y_test_4, result4)\n",
    "print(conf_mat_4)\n",
    "\n",
    "resultsDf = pd.concat([resultsDf, pd.DataFrame({'Method':['LinearSVC + TfidfVectorizer all'], \n",
    "                          'Accuracy': [acc4],\n",
    "                          'Correct Negative': conf_mat_4[0,0], \n",
    "                          'Correct Neutral': conf_mat_4[1,1],\n",
    "                          'Correct Positive': conf_mat_4[2,2]})])\n",
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Correct Negative</th>\n",
       "      <th>Correct Neutral</th>\n",
       "      <th>Correct Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer 1000</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>2415</td>\n",
       "      <td>543</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer 1000</td>\n",
       "      <td>0.781193</td>\n",
       "      <td>2461</td>\n",
       "      <td>517</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + CountVectorizer all</td>\n",
       "      <td>0.784608</td>\n",
       "      <td>2399</td>\n",
       "      <td>562</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LinearSVC + TfidfVectorizer all</td>\n",
       "      <td>0.782332</td>\n",
       "      <td>2619</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Method  Accuracy  Correct Negative  \\\n",
       "0  LinearSVC + CountVectorizer 1000  0.778689  2415               \n",
       "0  LinearSVC + TfidfVectorizer 1000  0.781193  2461               \n",
       "0  LinearSVC + CountVectorizer all   0.784608  2399               \n",
       "0  LinearSVC + TfidfVectorizer all   0.782332  2619               \n",
       "\n",
       "   Correct Neutral  Correct Positive  \n",
       "0  543              462               \n",
       "0  517              453               \n",
       "0  562              485               \n",
       "0  404              413               "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pre-processing and Vectorization methods convert data to numbers, so that we can feed the data in the model.\n",
    "* Adding more bigrams and trigrams features seems to increase model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
